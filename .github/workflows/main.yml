name: Scrape AniWatch Data

on:
  push:
    branches:
      - main
  schedule:
    # Jalankan setiap 12 jam (proses ini lebih berat dan butuh waktu)
    - cron: '0 */12 * * *'
  workflow_dispatch: # Izinkan pemicuan manual dari tab Actions

jobs:
  scrape:
    runs-on: ubuntu-latest
    # Beri waktu hingga 20 menit, karena proses browser bisa lambat
    timeout-minutes: 20

    # PENTING: Beri izin pada Action untuk menulis (commit & push) ke repo Anda
    permissions:
      contents: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      # Langkah paling penting: Menginstal Playwright, library stealth, dan browser
      - name: Install Playwright and Stealth Dependencies
        run: |
          python -m pip install --upgrade pip
          # Menginstal library python untuk playwright dan playwright-stealth
          pip install playwright playwright-stealth
          # Menginstal browser Chromium beserta dependensi sistem yang dibutuhkan di Linux
          playwright install --with-deps chromium

      - name: Run scraper
        run: python scraper.py

      - name: Commit and push if there are changes
        run: |
          # Konfigurasi git agar bot bisa melakukan commit
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          
          # Tambahkan file hasil scrape ke staging area
          git add anime_data.json
          
          # Cek apakah ada perubahan. Jika ada, lakukan commit dan push.
          # Ini mencegah commit kosong jika data tidak berubah.
          git diff --staged --quiet || (git commit -m "Update anime data" && git push)
